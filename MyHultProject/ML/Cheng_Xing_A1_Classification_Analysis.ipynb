{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "catholic-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595707\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM - !CHOOSE THIS!</td>\n",
       "      <td>0.907654</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.826021</td>\n",
       "      <td>[[300, 30], [85, 246]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.722800</td>\n",
       "      <td>(65, 91, 44, 287)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.650900</td>\n",
       "      <td>(74, 82, 88, 243)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.681300</td>\n",
       "      <td>0.679700</td>\n",
       "      <td>(1, 155, 1, 330)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Name  AUC Score  Training Accuracy  Testing Accuracy        Confusion Matrix\n",
       "3  GBM - !CHOOSE THIS!    0.907654           0.998486          0.826021  [[300, 30], [85, 246]]\n",
       "2           Pruned Tree   0.641900           0.727200          0.722800       (65, 91, 44, 287)\n",
       "1             Full Tree   0.604200           1.000000          0.650900       (74, 82, 88, 243)\n",
       "0              Logistic   0.501700           0.681300          0.679700        (1, 155, 1, 330)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random as rand                     # random number gen\n",
    "import pandas as pd                       # data science essentials\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn as sns                      # enhanced data viz\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO           # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus   # interprets dot objects\n",
    "from sklearn.model_selection import train_test_split   # train-test split\n",
    "from sklearn.metrics import roc_auc_score              # auc score\n",
    "from sklearn.model_selection import RandomizedSearchCV # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                # customizable scorer\n",
    "from sklearn.metrics import confusion_matrix           # confusion matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height=500, width=800):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree=tree,\n",
    "                    out_file=dot_data,\n",
    "                    filled=True,\n",
    "                    rounded=True,\n",
    "                    special_characters=True,\n",
    "                    feature_names=feature_df.columns)\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height=height,\n",
    "                width=width)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export=False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "\n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "\n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')\n",
    "\n",
    "\n",
    "chef = pd.read_excel('Apprentice_Chef_Dataset.xlsx')\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "\n",
    "    df[new_col_name] = 0\n",
    "\n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep=' '))\n",
    "\n",
    "text_split_feature(col='NAME',df=chef)\n",
    "\n",
    "chef['number_of_names'].value_counts().sort_index()\n",
    "one_hot_num_name = pd.get_dummies(chef['number_of_names'])\n",
    "\n",
    "#set the log functions\n",
    "chef = chef.drop(['REVENUE', 'NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME', \n",
    "                        'UNIQUE_MEALS_PURCH', 'PRODUCT_CATEGORIES_VIEWED'], axis=1)\n",
    "\n",
    "chef_data = chef.drop(['CROSS_SELL_SUCCESS'], axis=1)\n",
    "chef_target = chef['CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(chef_data, chef_target, test_size=0.25, random_state=219,\n",
    "                                                    stratify=chef_target)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "chef_train = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula = \"\"\"CROSS_SELL_SUCCESS ~\n",
    "MOBILE_NUMBER +\n",
    "CANCELLATIONS_BEFORE_NOON +\n",
    "CANCELLATIONS_AFTER_NOON +\n",
    "TASTES_AND_PREFERENCES +\n",
    "PC_LOGINS +\n",
    "EARLY_DELIVERIES +\n",
    "CONTACTS_W_CUSTOMER_SERVICE +\n",
    "MOBILE_LOGINS +\n",
    "WEEKLY_PLAN +\n",
    "LATE_DELIVERIES +\n",
    "PACKAGE_LOCKER +\n",
    "REFRIGERATED_LOCKER +\n",
    "AVG_PREP_VID_TIME +\n",
    "LARGEST_ORDER_SIZE +\n",
    "MASTER_CLASSES_ATTENDED +\n",
    "MEDIAN_MEAL_RATING +\n",
    "AVG_CLICKS_PER_VISIT +\n",
    "TOTAL_PHOTOS_VIEWED +\n",
    "TOTAL_MEALS_ORDERED +\n",
    "AVG_TIME_PER_SITE_VISIT\n",
    "\"\"\", data=chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "# train/test split with the full model\n",
    "chef_data_sig = chef.loc[:, ['CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'PC_LOGINS',\n",
    "                             'EARLY_DELIVERIES']]\n",
    "chef_target_sig = chef['CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train_sig, x_test_sig, y_train_sig, y_test_sig = train_test_split(\n",
    "            chef_data_sig,\n",
    "            chef_target_sig,\n",
    "            random_state=219,\n",
    "            test_size=0.25,\n",
    "            stratify=chef_target_sig)\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train_sig, y_train_sig)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test_sig)\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train_sig, y_train_sig).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test_sig, y_test_sig).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test_sig, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test_sig,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)\n",
    "\n",
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', 'PC_LOGINS',\n",
    "                           'EARLY_DELIVERIES'],\n",
    "                          logreg_fit.coef_.ravel().round(decimals=2))\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals=2))]\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "\n",
    "#Tree\n",
    "########################################\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# calling display_tree\n",
    "display_tree(tree       = full_tree_fit,\n",
    "             feature_df = x_train)\n",
    "\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "################\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc\n",
    "\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "\n",
    "    'Model Name': ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "\n",
    "    'AUC Score': [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "\n",
    "    'Training Accuracy': [logreg_train_score, full_tree_train_score,\n",
    "                          pruned_tree_train_score],\n",
    "\n",
    "    'Testing Accuracy': [logreg_test_score, full_tree_test_score,\n",
    "                         pruned_tree_test_score],\n",
    "\n",
    "    'Confusion Matrix': [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                         (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                         (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "#单独改良的GBM模型\n",
    "#!pip3 install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# read data from excel file\n",
    "df = pd.read_excel('Apprentice_Chef_Dataset.xlsx')\n",
    "data = df.drop(columns = ['REVENUE', 'NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME', \n",
    "                        'UNIQUE_MEALS_PURCH', 'PRODUCT_CATEGORIES_VIEWED'])\n",
    "# split x and y\n",
    "df_y = chef['CROSS_SELL_SUCCESS']\n",
    "df_X = chef.drop(['CROSS_SELL_SUCCESS'], axis=1)\n",
    "\n",
    "ros = RandomOverSampler(random_state=219)\n",
    "X_resampled, y_resampled  =  ros.fit_sample(df_X, df_y)\n",
    "# Normalize features\n",
    "X_resampled = (X_resampled - np.min(X_resampled)) / (np.max(X_resampled) - np.min(X_resampled)).values\n",
    "# target variable is stratified\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.25, random_state=219, stratify=y_resampled)\n",
    "# max_depth for classification tree, random forest, and gradient boosted machine (GBM) models is less than or equal to 8\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(random_state=219, max_depth=7)\n",
    "# train\n",
    "model.fit(x_train ,y_train)\n",
    "# predict\n",
    "ygbm_pred = model.predict(x_test)\n",
    "# Training Accuracy\n",
    "traingbm_acc = model.score(x_train, y_train)\n",
    "# Testing Accuracy\n",
    "testgbm_acc = model.score(x_test, y_test)\n",
    "# Confusion Matrix\n",
    "cmgbm = confusion_matrix(y_test, ygbm_pred)\n",
    "# AUC Score\n",
    "# roc_auc_score(y_test, model.decision_function(x_test))\n",
    "aucgbm = roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'GBM - !CHOOSE THIS! ',\n",
    "                          'Training Accuracy'  : traingbm_acc,\n",
    "                          'Testing Accuracy'   : testgbm_acc,\n",
    "                          'AUC Score'          : aucgbm,\n",
    "                          'Confusion Matrix'   : cmgbm},\n",
    "                          ignore_index = True)\n",
    "############################################\n",
    "# checking the results\n",
    "model_performance\n",
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)\n",
    "\n",
    "#the result may spend some time, please wait for it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-percentage",
   "metadata": {},
   "source": [
    "The second task is to do classification analysis, which is a more comprehensive way to analyze data by building different models. We chose CROSS_SELL_SUCCESS and other related data so that we can make better predictions and choose a better development plan for the company. The highest AUC score is the GBM model, which has 0.907."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-maria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
