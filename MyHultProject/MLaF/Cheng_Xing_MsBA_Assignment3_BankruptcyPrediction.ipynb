{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Application in Finance\n",
    "# &emsp; NNO6459-BNNO1, Spring 2021\n",
    "\n",
    "### &emsp; &emsp; Professor: Philip Sun\n",
    "### &emsp; &emsp; Email: philip.sun@faculty.hult.edu\n",
    "### &emsp; &emsp; Last Modified: 3/1/2021\n",
    "\n",
    "___\n",
    "\n",
    "## Class 3: Bankruptcy, Logistic Regression, and Neural Networks\n",
    "\n",
    "\n",
    "## &emsp; Ex1 Predict Company Bankcruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt?</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>operating gross margin</th>\n",
       "      <th>realized sales gross margin</th>\n",
       "      <th>operating profit rate</th>\n",
       "      <th>tax Pre-net interest rate</th>\n",
       "      <th>after-tax net interest rate</th>\n",
       "      <th>non-industry income and expenditure/revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>one if total liabilities exceeds total assets zero otherwise</th>\n",
       "      <th>net income to total assets</th>\n",
       "      <th>No-credit interval</th>\n",
       "      <th>Gross profit to Sales</th>\n",
       "      <th>Net income to stockholder's Equity</th>\n",
       "      <th>liability to equity</th>\n",
       "      <th>Degree of financial leverage (DFL)</th>\n",
       "      <th>Interest coverage ratio( Interest expense to EBIT )</th>\n",
       "      <th>one if net income was negative for the last two year zero otherwise</th>\n",
       "      <th>equity to liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.539468</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.604462</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.623620</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.566193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>0.598306</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.278132</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.566018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.610444</td>\n",
       "      <td>0.610213</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.809317</td>\n",
       "      <td>0.303512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.624156</td>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0</td>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.559911</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.607846</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.277547</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.801987</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.313415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.626680</td>\n",
       "      <td>0.627408</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.275114</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.565167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6819 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
       "0             1                                           0.370594          \n",
       "1             1                                           0.464291          \n",
       "2             1                                           0.426071          \n",
       "3             1                                           0.399844          \n",
       "4             1                                           0.465022          \n",
       "...         ...                                                ...          \n",
       "6814          0                                           0.493687          \n",
       "6815          0                                           0.475162          \n",
       "6816          0                                           0.472725          \n",
       "6817          0                                           0.506264          \n",
       "6818          0                                           0.493053          \n",
       "\n",
       "       ROA(A) before interest and % after tax  \\\n",
       "0                                    0.424389   \n",
       "1                                    0.538214   \n",
       "2                                    0.499019   \n",
       "3                                    0.451265   \n",
       "4                                    0.538432   \n",
       "...                                       ...   \n",
       "6814                                 0.539468   \n",
       "6815                                 0.538269   \n",
       "6816                                 0.533744   \n",
       "6817                                 0.559911   \n",
       "6818                                 0.570105   \n",
       "\n",
       "       ROA(B) before interest and depreciation after tax  \\\n",
       "0                                              0.405750    \n",
       "1                                              0.516730    \n",
       "2                                              0.472295    \n",
       "3                                              0.457733    \n",
       "4                                              0.522298    \n",
       "...                                                 ...    \n",
       "6814                                           0.543230    \n",
       "6815                                           0.524172    \n",
       "6816                                           0.520638    \n",
       "6817                                           0.554045    \n",
       "6818                                           0.549548    \n",
       "\n",
       "       operating gross margin   realized sales gross margin  \\\n",
       "0                    0.601457                      0.601457   \n",
       "1                    0.610235                      0.610235   \n",
       "2                    0.601450                      0.601364   \n",
       "3                    0.583541                      0.583541   \n",
       "4                    0.598783                      0.598783   \n",
       "...                       ...                           ...   \n",
       "6814                 0.604455                      0.604462   \n",
       "6815                 0.598308                      0.598308   \n",
       "6816                 0.610444                      0.610213   \n",
       "6817                 0.607850                      0.607850   \n",
       "6818                 0.627409                      0.627409   \n",
       "\n",
       "       operating profit rate   tax Pre-net interest rate  \\\n",
       "0                   0.998969                    0.796887   \n",
       "1                   0.998946                    0.797380   \n",
       "2                   0.998857                    0.796403   \n",
       "3                   0.998700                    0.796967   \n",
       "4                   0.998973                    0.797366   \n",
       "...                      ...                         ...   \n",
       "6814                0.998992                    0.797409   \n",
       "6815                0.998992                    0.797414   \n",
       "6816                0.998984                    0.797401   \n",
       "6817                0.999074                    0.797500   \n",
       "6818                0.998080                    0.801987   \n",
       "\n",
       "       after-tax net interest rate  \\\n",
       "0                         0.808809   \n",
       "1                         0.809301   \n",
       "2                         0.808388   \n",
       "3                         0.808966   \n",
       "4                         0.809304   \n",
       "...                            ...   \n",
       "6814                      0.809331   \n",
       "6815                      0.809327   \n",
       "6816                      0.809317   \n",
       "6817                      0.809399   \n",
       "6818                      0.813800   \n",
       "\n",
       "       non-industry income and expenditure/revenue  ...  \\\n",
       "0                                         0.302646  ...   \n",
       "1                                         0.303556  ...   \n",
       "2                                         0.302035  ...   \n",
       "3                                         0.303350  ...   \n",
       "4                                         0.303475  ...   \n",
       "...                                            ...  ...   \n",
       "6814                                      0.303510  ...   \n",
       "6815                                      0.303520  ...   \n",
       "6816                                      0.303512  ...   \n",
       "6817                                      0.303498  ...   \n",
       "6818                                      0.313415  ...   \n",
       "\n",
       "      one if total liabilities exceeds total assets zero otherwise  \\\n",
       "0                                                     0              \n",
       "1                                                     0              \n",
       "2                                                     0              \n",
       "3                                                     0              \n",
       "4                                                     0              \n",
       "...                                                 ...              \n",
       "6814                                                  0              \n",
       "6815                                                  0              \n",
       "6816                                                  0              \n",
       "6817                                                  0              \n",
       "6818                                                  0              \n",
       "\n",
       "      net income to total assets  No-credit interval  Gross profit to Sales  \\\n",
       "0                       0.716845            0.622879               0.601453   \n",
       "1                       0.795297            0.623652               0.610237   \n",
       "2                       0.774670            0.623841               0.601449   \n",
       "3                       0.739555            0.622929               0.583538   \n",
       "4                       0.795016            0.623521               0.598782   \n",
       "...                          ...                 ...                    ...   \n",
       "6814                    0.799927            0.623620               0.604455   \n",
       "6815                    0.799748            0.623931               0.598306   \n",
       "6816                    0.797778            0.624156               0.610441   \n",
       "6817                    0.811808            0.623957               0.607846   \n",
       "6818                    0.815956            0.626680               0.627408   \n",
       "\n",
       "      Net income to stockholder's Equity  liability to equity  \\\n",
       "0                               0.827890             0.290202   \n",
       "1                               0.839969             0.283846   \n",
       "2                               0.836774             0.290189   \n",
       "3                               0.834697             0.281721   \n",
       "4                               0.839973             0.278514   \n",
       "...                                  ...                  ...   \n",
       "6814                            0.840359             0.279606   \n",
       "6815                            0.840306             0.278132   \n",
       "6816                            0.840138             0.275789   \n",
       "6817                            0.841084             0.277547   \n",
       "6818                            0.841019             0.275114   \n",
       "\n",
       "      Degree of financial leverage (DFL)  \\\n",
       "0                               0.026601   \n",
       "1                               0.264577   \n",
       "2                               0.026555   \n",
       "3                               0.026697   \n",
       "4                               0.024752   \n",
       "...                                  ...   \n",
       "6814                            0.027064   \n",
       "6815                            0.027009   \n",
       "6816                            0.026791   \n",
       "6817                            0.026822   \n",
       "6818                            0.026793   \n",
       "\n",
       "      Interest coverage ratio( Interest expense to EBIT )  \\\n",
       "0                                              0.564050     \n",
       "1                                              0.570175     \n",
       "2                                              0.563706     \n",
       "3                                              0.564663     \n",
       "4                                              0.575617     \n",
       "...                                                 ...     \n",
       "6814                                           0.566193     \n",
       "6815                                           0.566018     \n",
       "6816                                           0.565158     \n",
       "6817                                           0.565302     \n",
       "6818                                           0.565167     \n",
       "\n",
       "      one if net income was negative for the last two year zero otherwise  \\\n",
       "0                                                     1                     \n",
       "1                                                     1                     \n",
       "2                                                     1                     \n",
       "3                                                     1                     \n",
       "4                                                     1                     \n",
       "...                                                 ...                     \n",
       "6814                                                  1                     \n",
       "6815                                                  1                     \n",
       "6816                                                  1                     \n",
       "6817                                                  1                     \n",
       "6818                                                  1                     \n",
       "\n",
       "      equity to liability  \n",
       "0                0.016469  \n",
       "1                0.020794  \n",
       "2                0.016474  \n",
       "3                0.023982  \n",
       "4                0.035490  \n",
       "...                   ...  \n",
       "6814             0.029890  \n",
       "6815             0.038284  \n",
       "6816             0.097649  \n",
       "6817             0.044009  \n",
       "6818             0.233902  \n",
       "\n",
       "[6819 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import bankruptcy data\n",
    "# download the following data file from mycourse page, and store it in the same directory as the notebook file\n",
    "csv_file='CompanyBankruptcy_Clean.csv'\n",
    "df_bankruptcy=pd.read_csv(csv_file, index_col=0)\n",
    "df_bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Interest coverage ratio( Interest expense to EBIT )')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw scatter plot(s) for class slides:\n",
    "\n",
    "#xlabel='liability to equity'\n",
    "#xlabel='Degree of financial leverage (DFL)'\n",
    "xlabel='Interest coverage ratio( Interest expense to EBIT )'\n",
    "\n",
    "x=df_bankruptcy[xlabel]\n",
    "y=df_bankruptcy['Bankrupt?']\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.title('Bankruptcy')\n",
    "plt.xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and output some summary statistics\n",
    "\n",
    "def stat_summary(df_data, to_print):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    stat_count=len(df_data.index)\n",
    "    stat_mean=np.mean(df_data)\n",
    "    stat_std=np.std(df_data)\n",
    "    stat_max=np.max(df_data)\n",
    "    stat_90pct=np.percentile(df_data, 90)\n",
    "    stat_median=np.median(df_data)\n",
    "    stat_min=np.min(df_data)\n",
    "\n",
    "        \n",
    "    #return\n",
    "    df_stat_summary=pd.DataFrame({'count': len(df_data.index),\n",
    "                    'mean': np.mean(df_data, axis=0),\n",
    "                    'stdev': np.std(df_data, axis=0),\n",
    "                    'stat_max': np.max(df_data, axis=0),\n",
    "                    'stat_90pct': np.percentile(df_data, 90, axis=0),\n",
    "                    'stat_75pct': np.percentile(df_data, 75, axis=0),\n",
    "                    'stat_media': np.median(df_data, axis=0),\n",
    "                    'stat_25pct': np.percentile(df_data, 25, axis=0),\n",
    "                    'stat_10pct': np.percentile(df_data, 10, axis=0),\n",
    "                    'stat_min': np.min(df_data, axis=0)} ,\n",
    "                     index = df_data.columns)\n",
    "    \n",
    "    #print?\n",
    "    if to_print:\n",
    "        print(df_stat_summary)\n",
    "        \n",
    "    return df_stat_summary\n",
    "# end of function stat_summary\n",
    "\n",
    "\n",
    "df_stat=stat_summary(df_bankruptcy, False)\n",
    "df_stat.to_csv('csv_out.csv') # this is the .csv output file.  open to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE, the dataset has been cleaned to remove some outliers.  following were codes used to clean the original data from kaggle.com\n",
    "# csv_file='CompanyBankruptcy.csv'\n",
    "# df_bankruptcy=pd.read_csv(csv_file, index_col=0)\n",
    "# df_bankruptcy.drop(df_bankruptcy.columns[df_stat['stat_max']>1.0e+8], axis=1, inplace=True)\n",
    "# df_bankruptcy.dropna\n",
    "# df_bankruptcy.to_csv('CompanyBankruptcy_Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first split the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=np.array(df_bankruptcy.iloc[:,1:]) # get features from df, convert to array for easy numerical operation\n",
    "y=np.array(df_bankruptcy.iloc[:,0]) # get target, note y=1 for bankruptcy, 0 for no bankruptcy\n",
    "\n",
    "# splitting into training, and test\n",
    "# note: use stratify as y=1 is rare (~3% of total observation). stratify ensures that positives are split proportionally\n",
    "Xtra, Xtest, ytra, ytest = train_test_split(X, y, stratify=y, test_size=0.20, random_state=0)\n",
    "# further split training into train and validation\n",
    "Xtra, Xval, ytra, yval = train_test_split(Xtra, ytra, stratify=ytra, test_size=0.25, random_state=0)\n",
    "# final split is 60:20:20, tra:val:test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score (accuracy):   0.9709117575164996\n",
      "validation score (accuracy):   0.967008797653959\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Logit_Reg=LogisticRegression(random_state=0).fit(Xtra, ytra)\n",
    "\n",
    "print('training score (accuracy):  ', Logit_Reg.score(Xtra,ytra))\n",
    "print('validation score (accuracy):  ', Logit_Reg.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function, i.e. the linear function theta'*x: \n",
      " [-2.80896605 -4.19877811 -4.32733405 ... -6.34150291 -5.46659652\n",
      " -4.66269985] \n",
      "\n",
      "Decision function min: -10.77 max: 4.17 \n",
      "\n",
      "Predicition probability, i.e. the sigmoid function g(theta*x): \n",
      " [0.94315841 0.98520817 0.98696934 ... 0.99824145 0.99579219 0.99064736] \n",
      "\n",
      "Predicition probability min: 0.02 max: 1.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a Look at Prediction\n",
    "decfun_val=Logit_Reg.decision_function(Xval)\n",
    "print(\"Decision function, i.e. the linear function theta'*x: \\n\", decfun_val, \"\\n\")\n",
    "print(\"Decision function min: {:.2f} max: {:.2f} \\n\".format(np.min(decfun_val), np.max(decfun_val)))\n",
    "\n",
    "prob_val=Logit_Reg.predict_proba(Xval)\n",
    "print(\"Predicition probability, i.e. the sigmoid function g(theta*x): \\n\", prob_val[:,0], \"\\n\")\n",
    "print(\"Predicition probability min: {:.2f} max: {:.2f} \\n\".format(np.min(prob_val[:,0]), np.max(prob_val[:,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Neural Network (Deep Learning)\n",
    "In sklearn, the neural_network package is pretty good for small dataset.  for more computational demanding tasks check out kera, tensorflow, or other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score (accuracy):   0.9689562454167685\n",
      "validation score (accuracy):   0.969208211143695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# there are many parameters here\n",
    "# * solver (previously algorithm), default 'adam' does a good job.  other options like 'lbfgs' more robust but slower\n",
    "# * activation is the function applied, there is 'tanh' is similar to sigmoid, \n",
    "#     it uses sigmoid tangent function betwee -1 and +1\n",
    "# * max_iter gives the maximimun iteration (of gradient descent).  if opt does not converge, it will stop at max_iter.\n",
    "#     we will start with 1000, and will increase to 10,000\n",
    "# * alpha is the regularization parameter. higher alpha, means more regularization (i.e. shrink coef more)\n",
    "# * hidden_layer, specifies how many hidden layer and how many nodes per layer.\n",
    "\n",
    "nn_01 = MLPClassifier(solver='adam', activation='tanh', \n",
    "                      max_iter=1000, alpha=0.01, random_state=0, \n",
    "                      hidden_layer_sizes=[10, 10]).fit(Xtra, ytra)\n",
    "\n",
    "print('training score (accuracy):  ', nn_01.score(Xtra,ytra))\n",
    "print('validation score (accuracy):  ', nn_01.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score (accuracy):   0.9689562454167685\n",
      "validation score (accuracy):   0.969208211143695\n"
     ]
    }
   ],
   "source": [
    "# what if we add a layer\n",
    "nn_02 = MLPClassifier(solver='adam', activation='tanh', \n",
    "                      max_iter=10000, alpha=1, random_state=0, \n",
    "                      hidden_layer_sizes=[16, 8, 4]).fit(Xtra, ytra)\n",
    "\n",
    "print('training score (accuracy):  ', nn_01.score(Xtra,ytra))\n",
    "print('validation score (accuracy):  ', nn_01.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3.a (graded) \n",
    "Run Neural Network fitting with 3 hidden layers with multiple alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0003</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0030</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0300</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3000</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0000</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train validation\n",
       "0.0001  0.970667   0.967742\n",
       "0.0003  0.970667   0.967742\n",
       "0.0010  0.970667   0.967742\n",
       "0.0030  0.970667   0.967742\n",
       "0.0100  0.970667   0.967742\n",
       "0.0300  0.970667   0.967742\n",
       "0.1000  0.970667   0.967742\n",
       "0.3000  0.970667   0.967742\n",
       "1.0000  0.970667   0.967742\n",
       "3.0000  0.970667   0.967742"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through alpha in a range and collect scores, and print at the end. \n",
    "alpharange=[0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "hidden_layer=[16, 8, 4]\n",
    "df_accuracy=pd.DataFrame([], index=alpharange, columns=['train','validation'])\n",
    "for a in alpharange:\n",
    "    # complete the code to fit MLPClassifier in this for loop\n",
    "    nn_00 = MLPClassifier(solver='adam', activation='tanh', \n",
    "                      max_iter=10000, alpha=1, random_state=0, \n",
    "                      hidden_layer_sizes=[16, 8, 4]).fit(Xtra, ytra)\n",
    "\n",
    "    \n",
    "    # collect results, i.e. prediction scores\n",
    "    df_accuracy.loc[a,:]=[nn_00.score(Xtra,ytra),nn_00.score(Xval,yval)]\n",
    "    \n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3.b (graded)\n",
    "run Neural Network fitting with randomized initialization, and collect the accuracy scores in a dataframe indexed by the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train validation\n",
       "0  0.969934   0.970674\n",
       "1  0.969934   0.970674\n",
       "2  0.969934   0.970674\n",
       "3  0.969934   0.970674\n",
       "4  0.969934   0.970674\n",
       "5  0.969934   0.970674\n",
       "6  0.969934   0.970674\n",
       "7  0.969934   0.970674\n",
       "8  0.969934   0.970674\n",
       "9  0.969934   0.970674"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through alpha in a range and collect scores, and print at the end. \n",
    "alpha_value=0.01\n",
    "hidden_layer=[16, 8, 4]\n",
    "df_accuracy=pd.DataFrame([], index=range(10), columns=['train','validation'])\n",
    "for i in range(10):\n",
    "    # complete the code to fit MLPClassifier in this for loop\n",
    "    nn_01= MLPClassifier(solver='adam', activation='tanh', \n",
    "                      max_iter=10000, alpha=0.01, random_state=0, \n",
    "                      hidden_layer_sizes=[16, 8, 4]).fit(Xtra, ytra)\n",
    "    \n",
    "    # collect results, i.e. prediction scores\n",
    "    df_accuracy.loc[i,:]=[nn_01.score(Xtra,ytra), nn_01.score(Xval,yval)]\n",
    "    \n",
    "df_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3.c (optional)\n",
    "compute a balanced F1 Score and report in addition to accuracy score (see Wikipedia entry below for definition)\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: make a prediction from the model. then count the number of true/false positives and true/false negatives etc.\n",
    "\n",
    "# finally compute F1 as F1=2*tp/(2*tp+fp+fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
